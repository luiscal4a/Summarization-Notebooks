{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Szr5955mHNT"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import re\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8XtgW2Qn1HE"
   },
   "source": [
    "Copy drive folder with txt scientific papers to environment. You will be required to give access to your google drive. This step can be skipped if the data input comes from another source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wQ4zcssTnr0E"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/drive/')\n",
    "!rm -r \"/content/data\"\n",
    "!cp -r \"/content/drive/MyDrive/[Personal-route-papers]\" \"/content/data/\"\n",
    "drive.flush_and_unmount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAVVb4k1obC-"
   },
   "source": [
    "Define function to extract a txt file imported to the environment by its name and separate its abstract from the rest of the content. Acknowledgements and references are ignored. A correct execution of this function will result in both components of the paper being added to the processed papers list. If the function is incapable of separating abstract and content, the paper will be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lEe3QzrApTbO"
   },
   "outputs": [],
   "source": [
    "processed_papers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kLkBUsTjGWpq"
   },
   "outputs": [],
   "source": [
    "def processPaper(paper_name):\n",
    "  paper_full = open(f\"/content/data/{paper_name}.txt\", \"r\", encoding=\"utf8\").read()\n",
    "  #Remove non ascii characters\n",
    "  paper_full = paper_full.encode(\"ascii\", \"ignore\").decode()\n",
    "  #Divide Abstract from rest of the paper\n",
    "\n",
    "  intro_keywords = [\"introduction\", \"outline\", \"overview\", \"preliminaries\"]\n",
    "  #Create list with postion of first instance of each intro keyword in text\n",
    "  found_intro = [(re.search(r\"\\b\" + i + r\"\\b\", paper_full.lower(), flags=re.IGNORECASE).start(), i) for i in intro_keywords if re.search(r\"\\b\" + i + r\"\\b\", paper_full.lower(), flags=re.IGNORECASE)]\n",
    "\n",
    "  #Check if the text was divided by any of the keywords\n",
    "  if len(found_intro) > 0:\n",
    "    #Select as the abstract and content divider the first intro_keyword found\n",
    "    intro_marker = min(found_intro)[1]\n",
    "    split = re.split(r\"\\b\" + intro_marker + r\"\\b\", paper_full, flags=re.IGNORECASE)\n",
    "  \n",
    "    paper_divided = []\n",
    "    abstract = split[0]\n",
    "    content = ''.join(split[1:])\n",
    "\n",
    "    #Remove text over abstract title if it exists\n",
    "    abstract = re.split(\"Abstract\", abstract, flags=re.IGNORECASE)[-1]\n",
    "    if len(abstract) < 500:\n",
    "      return\n",
    "    #Remove references\n",
    "    if len(re.split(\"References\", content, flags=re.IGNORECASE)) > 1:\n",
    "      content = ''.join(re.split(\"References\", content, flags=re.IGNORECASE)[:-1])\n",
    "\n",
    "    paper_divided.append(abstract)\n",
    "    paper_divided.append(content)\n",
    "    processed_papers.append(paper_divided)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Pk3OuIDt-Ti"
   },
   "source": [
    "Iterate through each file in the environment and send all txt files to be divided into abstract and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bsVLhZ0-plPN"
   },
   "outputs": [],
   "source": [
    "processed_papers.clear()\n",
    "file_list = os.listdir('/content/data/')\n",
    "file_list.sort()\n",
    "\n",
    "\n",
    "for filename in file_list:\n",
    "  filename, file_extension = os.path.splitext(filename)\n",
    "  if file_extension == \".txt\":\n",
    "    processPaper(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmwIeSzFzkCo"
   },
   "source": [
    "Save array with papers divided by abstract and content to google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17485,
     "status": "ok",
     "timestamp": 1647776386178,
     "user": {
      "displayName": "Luis Cal Garc√≠a",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhPjZTmk38TzuEw_20DGL3Wu9KahsgParSAHbVS=s64",
      "userId": "04158079854351715142"
     },
     "user_tz": -60
    },
    "id": "TVoVg0V_zHTF",
    "outputId": "03265e00-246e-4a38-a6b5-f967485f806c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive/')\n",
    "pkl_file = open(f\"/content/drive/[Personal-route]/processed_papers.pkl\", \"wb\")\n",
    "pkl.dump(processed_papers, pkl_file)\n",
    "pkl_file.close()\n",
    "drive.flush_and_unmount()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPVWNC+VGArb6QHvW9+e/Ww",
   "collapsed_sections": [],
   "name": "1. Text preprocessing",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
